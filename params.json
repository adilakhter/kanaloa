{"name":"Kanaloa","tagline":"akka actor scala reactive","body":"\r\n[![Join the chat at https://gitter.im/iheartradio/kanaloa](https://badges.gitter.im/Join%20Chat.svg)](https://gitter.im/iheartradio/kanaloa?utm_source=badge&utm_medium=badge&utm_campaign=pr-badge&utm_content=badge)\r\n[![Build Status](https://travis-ci.org/iheartradio/kanaloa.svg)](https://travis-ci.org/iheartradio/kanaloa)\r\n\r\n# Kanaloa\r\n\r\n\r\n#### A set of work dispatchers implemented using Akka actors\r\nNote: kanaloa work dispatchers are not Akka [MessageDispatcher](http://doc.akka.io/docs/akka/snapshot/scala/dispatchers.html).\r\n\r\n### Motivation\r\n Kanaloa work dispatchers sit in front of your service and dispatches received work to them. They make your service more resilient through the following means:\r\n  1. **Auto scaling** - it dynamically figures out the optimal number of concurrent requests your service can handle, and make sure that at any given time your service handles no more than that number of concurrent requests. This simple mechanism was also ported and contributed to Akka's [Optimal Size Exploring Resizer](http://doc.akka.io/docs/akka/2.4.1/scala/routing.html#Optimal_Size_Exploring_Resizer) with some limitations. See details of the algorithm below.\r\n  2. **Back pressure control** - this control is [Little's law](https://en.wikipedia.org/wiki/Little%27s_law) inspired. It rejects requests when estimated wait time for which exceeds a certain threshold.\r\n  3. **Circuit breaker** - when error rate from your service goes above a certain threshold, the kanaloa dispatcher stops all requests for a short period of time to give your service a chance to \"cool down\".\r\n  4. **Real-time monitoring** - a built-in statsD reporter allows you to monitor a set of critical metrics (throughput, failure rate, queue length, expected wait time, service process time, number of concurrent requests, etc) in real time. It also provides real-time insights into how kanaloa dispatchers are working. An example on Grafana:\r\n  ![Dashboard](https://github.com/iheartradio/docker-grafana-graphite/blob/master/dashboard.png)\r\n\r\nFor the detailed algorithm please see the [implementation detail](#impl) below.\r\n\r\n### Get started\r\n\r\n#### Install dependency\r\n```\r\nresolvers += Resolver.jcenterRepo\r\n\r\nlibraryDependencies +=  \"com.iheart\" %% \"kanaloa\" % \"0.2.0\"\r\n```\r\n\r\n#### Config\r\nAn example of a `my-dispatcher`\r\n```\r\nkanaloa {\r\n  dispatchers {\r\n    my-service1 {\r\n      workerPool {\r\n       startingPoolSize = 8\r\n      }\r\n      workTimeout = 3s\r\n      circuitBreaker {\r\n        errorRateThreshold = 0.7\r\n      }\r\n    }\r\n  }\r\n}\r\n```\r\nFor more configuration settings and their documentation please see the [reference configuration](src/main/resources/reference.conf)\r\n\r\n#### Usage\r\n\r\nThere are two types kanaloa dispatchers: PushingDispatcher and PullingDispatcher.\r\n`PushingDispatcher` takes work requests when you send message to it.\r\n```Scala\r\nval system = ActorSystem()\r\n\r\n// suppose you wrote your service in an actor,\r\n// which takes a SomeWork(someRequest) message and\r\n// replies SuccessResult(someResults) when it succeeds\r\nval serviceActor = system.actorOf(MyServiceActor.props)\r\n\r\nval dispatcher =\r\n  system.actorOf(PushingDispatcher.props(\r\n    name = \"my-service1\",\r\n    serviceActor\r\n  ) {\r\n    case SuccessResult(r) => Right(r)  // ResultChecker that tells kanaloa if the request is handled succesffully\r\n    case _ => Left(\"shit happened\")\r\n  })\r\n\r\ndispatcher ! SomeWork(\"blahblah\") //dispatcher replies the result (whatever wrapped in the SuccessResult) back.\r\n\r\n```\r\n\r\n`PullingPatcher` pulls work from an iterator, ideal when you have control over the source of the work (e.g. a task iterates through your DB)\r\n```Scala\r\n//assume you have the same system and serviceActor as above.\r\n\r\n//unrealistic example of an iterator you would pass into a PullingDispatcher\r\nval iterator = List(SomeWork(\"work1\"), SomeWork(\"work2\"), SomeWork(\"work3\")).iterator\r\n\r\nval dispatcher =\r\n  system.actorOf(PullingDispatcher.props(\r\n    name = \"my-service2\",\r\n    iterator,\r\n    serviceActor\r\n  ) {\r\n    case SuccessResult(r) => Right(r)     // this is your ResultChecker which tell kanaloa if the request is handled succesffully\r\n    case _ => Left(\"shit happened\")\r\n  })\r\n\r\ndispatcher ! SomeWork(\"blahblah\") //dispatcher replies the result (whatever wrapped in the SuccessResult) back.\r\n\r\n\r\n```\r\n\r\nWe used an [ActorRef](http://doc.akka.io/api/akka/snapshot/index.html#akka.actor.ActorRef) as service here, Kanaloa also supports [Props](http://doc.akka.io/api/akka/snapshot/index.html#akka.actor.Props) and `T => Future[R]` function as service. You can use any `T` as service if you implement an implicit `T => Backend` where `Backend` is a simple trait:\r\n```\r\ntrait Backend { def apply(af: ActorRefFactory): ActorRef }\r\n```\r\n\r\n### StatsD monitor\r\n\r\nKanaloa has a built-in statsD reporter that allows users to monitor important metrics in real time.\r\n\r\n#### Config StatsD\r\nAdd following to your config\r\n```\r\nkanaloa {\r\n  metrics {\r\n    statsd {\r\n      host = \"localhost\" #host of your statsD server\r\n      port = 8125\r\n    }\r\n  }\r\n}\r\n```\r\nFor more settings please see the [reference configuration](src/main/resources/reference.conf)\r\n\r\n#### Visualize with Grafana\r\n\r\nWe provide a [grafana dashboard](grafana/dashboard.json) if you are using grafana for statsD visualization.\r\nWe also provide a [docker image](https://github.com/iheartradio/docker-grafana-graphite) with which you can quickly get up and running a statsD server and visualization web app. Please follow the instructions there.\r\n\r\n\r\n### <a name=\"impl\"></a>Implementation Detail\r\n\r\nDisclaimer: some of the follow descriptions were adapted from the documentation of Akka's [OptimalSizeExploringResizer](http://doc.akka.io/docs/akka/2.4.1/scala/routing.html#Optimal_Size_Exploring_Resizer), which was also written by the original author of this document.\r\n\r\nBehind the scene kanaloa dispatchers creates a set of workers that work with your services. These workers wait for result coming back from the service before they accept more work from the dispatcher. This way it controls the number of concurrent requests dispatchers send to services. It auto-scales the work pool to an optimal size that provides the highest throughput.\r\n\r\nThis auto-scaling works best when you expect the pool size to performance function to be a convex function, with which you can find a global optimal by walking towards a better size. For example CPU bound service may have an optimal worker pool size tied to the CPU cores available. When your service is IO bound, the optimal size is bound to optimal number of concurrent connections to that IO service - e.g. a 4 node elastic search cluster may handle 4-8 concurrent requests at optimal speed.\r\n\r\nThe dispatchers keep track of throughput at each pool size and performing the following three resizing operations (one at a time) periodically:\r\n\r\n1. Downsize if it hasn't seen all workers ever fully utilized for a period of time.\r\n2. Explore to a random nearby pool size to try and collect throughput metrics.\r\n3. Optimize to a nearby pool size with a better (than any other nearby sizes) throughput metrics.\r\n\r\nWhen the pool is fully-utilized (i.e. all workers are busy), it randomly choose between exploring and optimizing. When the pool has not been fully-utilized for a period of time, it will downsize the pool to the last seen max utilization multiplied by a configurable ratio.\r\n\r\nBy constantly exploring and optimizing, the resizer will eventually walk to the optimal size and remain nearby. When the optimal size changes it will start walking towards the new one.\r\n\r\n\r\n### Contribute\r\n\r\nAny contribution and feedback is more than welcome.\r\n\r\n\r\n### Special Thanks\r\n\r\nThe auto scaling algorithm was first suggested by @richdougherty. @ktoso kindly reviewed this library and provided valuable feedback.\r\n\r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}